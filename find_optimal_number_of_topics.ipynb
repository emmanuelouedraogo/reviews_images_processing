{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import pandas as pd # Assuming negative_reviews is a Pandas DataFrame/Series\n",
    "\n",
    "# --- Configuration du Logging ---\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# ==============================================================================\n",
    "# DÉFINITION DE LA FONCTION DE COHÉRENCE (Version adaptée pour Gensim)\n",
    "# ==============================================================================\n",
    "def get_Cv_gensim(model, texts, dictionary, coherence_type='c_v'):\n",
    "    \"\"\"\n",
    "    Calcule et renvoie le score de cohérence pour un modèle LDA Gensim.\n",
    "\n",
    "    Args:\n",
    "        model (gensim.models.ldamodel.LdaModel): Le modèle LDA entraîné.\n",
    "        texts (list of list of str): La liste des textes tokenisés.\n",
    "        dictionary (gensim.corpora.Dictionary): Le dictionnaire Gensim.\n",
    "        coherence_type (str, optional): Le type de mesure de cohérence ('c_v', 'u_mass', etc.).\n",
    "                                        Défaut à 'c_v'.\n",
    "\n",
    "    Returns:\n",
    "        float or None: Le score de cohérence, ou None en cas d'erreur.\n",
    "    \"\"\"\n",
    "    if not texts or not dictionary or not model:\n",
    "        logging.error(\"Modèle, Textes ou Dictionnaire manquant pour le calcul de cohérence.\")\n",
    "        return None\n",
    "    try:\n",
    "        coherence_model = CoherenceModel(\n",
    "            model=model,\n",
    "            texts=texts,\n",
    "            dictionary=dictionary,\n",
    "            coherence=coherence_type\n",
    "        )\n",
    "        coherence = coherence_model.get_coherence()\n",
    "        return coherence\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors du calcul de la cohérence ({coherence_type}) dans get_Cv_gensim: {e}\")\n",
    "        return None\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# DÉFINITION DE LA FONCTION POUR TROUVER LE NOMBRE OPTIMAL DE TOPICS\n",
    "# ==============================================================================\n",
    "def find_optimal_number_of_topics(dictionary, corpus, texts, limit, start=2, step=3, random_state=100, passes=10, iterations=50, chunksize=100, coherence_type='c_v'):\n",
    "    \"\"\"\n",
    "    Calcule les scores de cohérence pour différents nombres de topics et retourne\n",
    "    le nombre de topics optimal ainsi que les modèles et scores associés.\n",
    "\n",
    "    Args:\n",
    "        dictionary (gensim.corpora.Dictionary): Le dictionnaire Gensim.\n",
    "        corpus (list): Le corpus au format BoW Gensim.\n",
    "        texts (list of list of str): La liste des textes prétraités (liste de listes de tokens).\n",
    "        limit (int): Le nombre maximum de topics à tester (exclusif).\n",
    "        start (int, optional): Le nombre minimum de topics à tester. Défaut à 2.\n",
    "        step (int, optional): L'incrément entre les nombres de topics testés. Défaut à 3.\n",
    "        random_state (int, optional): Graine pour la reproductibilité. Défaut à 100.\n",
    "        passes (int, optional): Nombre de passes LDA. Défaut à 10.\n",
    "        iterations (int, optional): Nombre d'itérations LDA. Défaut à 50.\n",
    "        chunksize (int, optional): Taille des chunks LDA. Défaut à 100.\n",
    "        coherence_type (str, optional): Type de cohérence à utiliser ('c_v'). Défaut à 'c_v'.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        tuple: (optimal_num_topics, coherence_scores_dict)\n",
    "               - optimal_num_topics (int or None): Le nombre optimal de topics trouvé, ou None si échec.\n",
    "               - coherence_scores_dict (dict): Dictionnaire {num_topics: coherence_score}.\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = [] # Vous pourriez vouloir retourner cette liste si vous voulez les modèles\n",
    "    topic_numbers = list(range(start, limit, step))\n",
    "\n",
    "    if not topic_numbers:\n",
    "        logging.warning(f\"La plage de topics spécifiée (start={start}, limit={limit}, step={step}) est vide.\")\n",
    "        return None, {}\n",
    "\n",
    "    logging.info(f\"Début du calcul de cohérence ({coherence_type}) pour {len(topic_numbers)} modèles (topics de {start} à {limit-1} par pas de {step})...\")\n",
    "\n",
    "    for num_topics in topic_numbers:\n",
    "        logging.info(f\"Entraînement du modèle LDA pour {num_topics} topics...\")\n",
    "        try:\n",
    "            # Entraînement du modèle LDA Gensim\n",
    "            model = LdaModel( # Utilisation directe de LdaModel après import\n",
    "                corpus=corpus,\n",
    "                id2word=dictionary,\n",
    "                num_topics=num_topics,\n",
    "                random_state=random_state,\n",
    "                update_every=1,\n",
    "                chunksize=chunksize,\n",
    "                passes=passes,\n",
    "                iterations=iterations,\n",
    "                alpha='auto',\n",
    "                eta='auto',\n",
    "                per_word_topics=True # Nécessaire pour certaines visualisations, peut être False\n",
    "            )\n",
    "            model_list.append(model) # Stocker le modèle si besoin\n",
    "\n",
    "            # Calcul du score de cohérence\n",
    "            logging.debug(f\"Appel de get_Cv_gensim pour {num_topics} topics...\")\n",
    "            coherence = get_Cv_gensim(model=model, texts=texts, dictionary=dictionary, coherence_type=coherence_type)\n",
    "\n",
    "            if coherence is not None:\n",
    "                coherence_values.append(coherence)\n",
    "                logging.info(f\"Nombre de Topics = {num_topics} -> Score de Cohérence ({coherence_type}) = {coherence:.4f}\")\n",
    "            else:\n",
    "                logging.warning(f\"get_Cv_gensim a retourné None pour {num_topics} topics. Ce point sera ignoré.\")\n",
    "                coherence_values.append(None) # Ajouter None pour garder l'alignement avec topic_numbers\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erreur lors de l'entraînement ou du calcul de cohérence pour {num_topics} topics: {e}\")\n",
    "            coherence_values.append(None) # Ajouter None en cas d'erreur\n",
    "\n",
    "    # Filtrer les éventuels échecs (None) avant de chercher le max\n",
    "    # Créer une liste de tuples (nombre_topic, score) uniquement pour les scores valides\n",
    "    valid_scores_tuples = []\n",
    "    for i, score in enumerate(coherence_values):\n",
    "        if score is not None:\n",
    "            valid_scores_tuples.append((topic_numbers[i], score))\n",
    "\n",
    "    if not valid_scores_tuples:\n",
    "        logging.warning(f\"Aucun score de cohérence ({coherence_type}) n'a pu être calculé avec succès.\")\n",
    "        return None, {} # Retourner un dictionnaire vide pour les scores\n",
    "\n",
    "    # Trouver le nombre de topics avec le score maximal\n",
    "    optimal_num_topics, max_coherence = max(valid_scores_tuples, key=lambda item: item[1])\n",
    "    # Créer le dictionnaire final des scores valides\n",
    "    coherence_scores_dict = dict(valid_scores_tuples)\n",
    "\n",
    "    logging.info(f\"Calcul terminé. Nombre optimal de topics trouvé : {optimal_num_topics} (Score {coherence_type} = {max_coherence:.4f})\")\n",
    "\n",
    "    # Retourner le nombre optimal et le dictionnaire des scores\n",
    "    return optimal_num_topics, coherence_scores_dict\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# CHARGEMENT ET PRÉPARATION DES DONNÉES (EXEMPLE)\n",
    "# ==============================================================================\n",
    "# !!! Remplacez ceci par votre propre chargement et prétraitement de données !!!\n",
    "# Exemple: Supposons que vous ayez un DataFrame pandas 'df' avec une colonne 'text'\n",
    "# contenant vos textes déjà nettoyés et lemmatisés.\n",
    "data = {\n",
    "    'text': [\n",
    "        \"le service client est déplorable attente interminable\",\n",
    "        \"produit reçu cassé très déçu qualité médiocre\",\n",
    "        \"application bug souvent impossible utiliser correctement\",\n",
    "        \"livraison retardée sans aucune information utile\",\n",
    "        \"ne correspond pas description retour demandé\",\n",
    "        \"mauvaise expérience utilisateur interface compliquée\",\n",
    "        \"le support technique répond jamais aux emails\",\n",
    "        \"qualité prix pas justifiée trop cher pour ce que est\",\n",
    "        \"publicité mensongère sur les fonctionnalités réelles\",\n",
    "        \"annulation commande sans explication service nul\"\n",
    "    ]\n",
    "}\n",
    "negative_reviews = pd.DataFrame(data) # Crée un DataFrame exemple\n",
    "\n",
    "# --- Tokenisation ---\n",
    "# Utiliser text.split() est simple, mais un tokenizer plus avancé (NLTK, spaCy)\n",
    "# est souvent préférable pour mieux gérer la ponctuation, etc.\n",
    "# Assurez-vous que cette étape correspond à votre prétraitement réel.\n",
    "try:\n",
    "    # Assurez-vous que la colonne 'text' contient bien des chaînes de caractères\n",
    "    if not all(isinstance(text, str) for text in negative_reviews[\"text\"]):\n",
    "         raise TypeError(\"La colonne 'text' doit contenir des chaînes de caractères.\")\n",
    "\n",
    "    tokenized_texts = [text.lower().split() for text in negative_reviews[\"text\"]] # Ajout de .lower()\n",
    "    logging.info(f\"{len(tokenized_texts)} documents tokenisés.\")\n",
    "\n",
    "    # --- Création du Dictionnaire et du Corpus Gensim ---\n",
    "    dictionary = corpora.Dictionary(tokenized_texts)\n",
    "    # Optionnel: Filtrer les extrêmes (mots très rares ou très fréquents)\n",
    "    # dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    logging.info(f\"Dictionnaire créé avec {len(dictionary)} mots uniques.\")\n",
    "\n",
    "    corpus = [dictionary.doc2bow(text) for text in tokenized_texts]\n",
    "    logging.info(f\"Corpus créé avec {len(corpus)} documents.\")\n",
    "\n",
    "    # Vérification rapide que le corpus n'est pas vide\n",
    "    if not corpus or not any(corpus):\n",
    "         raise ValueError(\"Le corpus est vide ou tous les documents sont vides après tokenisation/filtrage.\")\n",
    "\n",
    "except KeyError:\n",
    "    logging.error(\"La colonne 'text' n'existe pas dans les données fournies (negative_reviews).\")\n",
    "    exit() # Arrêter si les données de base manquent\n",
    "except TypeError as te:\n",
    "     logging.error(f\"Erreur de type lors de la tokenisation : {te}. Vérifiez le contenu de 'negative_reviews['text']'.\")\n",
    "     exit()\n",
    "except ValueError as ve:\n",
    "     logging.error(f\"Erreur de valeur lors de la création du corpus : {ve}.\")\n",
    "     exit()\n",
    "except Exception as e:\n",
    "    logging.error(f\"Une erreur inattendue est survenue lors de la préparation des données : {e}\")\n",
    "    exit()\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# RECHERCHE DU NOMBRE OPTIMAL DE TOPICS\n",
    "# ==============================================================================\n",
    "# --- Paramètres pour la recherche ---\n",
    "start_topics = 2     # Nombre minimum de topics à tester\n",
    "limit_topics = 11    # Nombre maximum de topics à tester + 1 (range s'arrête avant)\n",
    "step_topics = 1      # Incrément entre les nombres de topics\n",
    "lda_passes = 10      # Nombre de passes pour l'entraînement LDA pendant la recherche\n",
    "lda_iterations = 50  # Nombre d'itérations pour l'entraînement LDA\n",
    "\n",
    "# --- Appel de la fonction ---\n",
    "optimal_topics, coherence_scores = find_optimal_number_of_topics(\n",
    "    dictionary=dictionary,\n",
    "    corpus=corpus,\n",
    "    texts=tokenized_texts, # Utiliser les textes tokenisés\n",
    "    limit=limit_topics,\n",
    "    start=start_topics,\n",
    "    step=step_topics,\n",
    "    passes=lda_passes,\n",
    "    iterations=lda_iterations,\n",
    "    coherence_type='c_v' # Spécifier 'c_v' explicitement si désiré\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# AFFICHAGE DES RÉSULTATS ET VISUALISATION\n",
    "# ==============================================================================\n",
    "if optimal_topics is not None:\n",
    "    print(f\"\\n--- Résultats de la Recherche ---\")\n",
    "    print(f\"Le nombre optimal de topics (basé sur la cohérence 'c_v') est : {optimal_topics}\")\n",
    "    print(\"Scores de cohérence ('c_v') par nombre de topics :\")\n",
    "    # Trier le dictionnaire par nombre de topics pour un affichage ordonné\n",
    "    sorted_scores = sorted(coherence_scores.items())\n",
    "    for topics, score in sorted_scores:\n",
    "        print(f\"  {topics} topics : {score:.4f}\")\n",
    "\n",
    "    # --- Visualisation des scores de cohérence ---\n",
    "    try:\n",
    "        x = list(coherence_scores.keys())\n",
    "        y = list(coherence_scores.values())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(x, y, marker='o', linestyle='-', color='b')\n",
    "        plt.xlabel(\"Nombre de Topics\")\n",
    "        plt.ylabel(\"Score de Cohérence (c_v)\")\n",
    "        plt.title(\"Évolution du Score de Cohérence (c_v) vs. Nombre de Topics\")\n",
    "        plt.xticks(range(start_topics, limit_topics, step_topics)) # Assurer des marques claires\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "        # Marquer le point optimal\n",
    "        if optimal_topics in coherence_scores:\n",
    "             plt.plot(optimal_topics, coherence_scores[optimal_topics], marker='X', color='red', markersize=12, linestyle='None', label=f'Optimal ({optimal_topics} topics)\\nScore={coherence_scores[optimal_topics]:.4f}')\n",
    "             plt.legend(loc='best')\n",
    "\n",
    "        plt.tight_layout() # Ajuster la mise en page\n",
    "        plt.show()\n",
    "\n",
    "    except ImportError:\n",
    "        logging.warning(\"Matplotlib non trouvé. Installez-le (`pip install matplotlib`) pour visualiser les scores.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de la création du graphique : {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nImpossible de déterminer le nombre optimal de topics avec les paramètres fournis.\")\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# OPTIONNEL : ENTRAÎNEMENT DU MODÈLE LDA FINAL AVEC LE NOMBRE OPTIMAL DE TOPICS\n",
    "# ==============================================================================\n",
    "if optimal_topics is not None:\n",
    "    print(f\"\\n--- Entraînement du Modèle LDA Final ---\")\n",
    "    print(f\"Entraînement du modèle LDA final avec {optimal_topics} topics...\")\n",
    "\n",
    "    # Vous pouvez augmenter les passes/itérations pour le modèle final\n",
    "    final_passes = 20\n",
    "    final_iterations = 100\n",
    "\n",
    "    try:\n",
    "        final_lda_model = LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=optimal_topics, # Utilisation de la variable optimale\n",
    "            random_state=100,          # Garder la même graine pour la reproductibilité\n",
    "            update_every=1,\n",
    "            chunksize=100,             # Garder les mêmes hyperparamètres que lors de la recherche\n",
    "            passes=final_passes,       # Ou utiliser des valeurs potentiellement plus élevées\n",
    "            iterations=final_iterations,\n",
    "            alpha='auto',\n",
    "            eta='auto',\n",
    "            per_word_topics=True       # Utile pour certaines analyses ultérieures\n",
    "        )\n",
    "        print(\"Modèle final entraîné avec succès.\")\n",
    "\n",
    "        # --- Afficher les topics du modèle final (Exemple) ---\n",
    "        print(f\"\\nTopics trouvés par le modèle final ({optimal_topics} topics):\")\n",
    "        # Utiliser print_topics pour une meilleure lisibilité\n",
    "        topics = final_lda_model.print_topics(num_words=10) # Afficher les 10 mots principaux par topic\n",
    "        for topic_num, topic_words in topics:\n",
    "            print(f\"Topic {topic_num}: {topic_words}\")\n",
    "\n",
    "        # Vous pouvez maintenant utiliser 'final_lda_model' pour d'autres tâches\n",
    "        # (ex: classification, analyse de documents spécifiques, etc.)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erreur lors de l'entraînement du modèle LDA final : {e}\")\n",
    "\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\nScript terminé.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openpy3.12.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
